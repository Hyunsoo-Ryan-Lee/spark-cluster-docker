{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74ded05b-7813-4bd0-867f-10194f98982a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark =  SparkSession \\\n",
    "        .builder \\\n",
    "        .appName('pyspark-init') \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead52d22",
   "metadata": {},
   "source": [
    "- enableHiveSupport() X : 임시 테이블만 생성되고 CREATE TABLE 쿼리는 적용이 안된다.\n",
    "- enableHiveSupport() O : hive로 영구 저장소가 생성되며 DB 처럼 다룰 수 있다. 세션 종료되어도 테이블 조회 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "993bb966",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+------------+----------+----------------+--------------------+------+-------------+----------+\n",
      "|Acceleration|Cylinders|Displacement|Horsepower|Miles_per_Gallon|                Name|Origin|Weight_in_lbs|      Year|\n",
      "+------------+---------+------------+----------+----------------+--------------------+------+-------------+----------+\n",
      "|        12.0|        8|       307.0|       130|            18.0|chevrolet chevell...|   USA|         3504|1970-01-01|\n",
      "|        11.5|        8|       350.0|       165|            15.0|   buick skylark 320|   USA|         3693|1970-01-01|\n",
      "|        11.0|        8|       318.0|       150|            18.0|  plymouth satellite|   USA|         3436|1970-01-01|\n",
      "+------------+---------+------------+----------+----------------+--------------------+------+-------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cars = spark.read.option(\"inferSchema\", \"true\").json(\"./dataset/cars.json\")\n",
    "cars.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b9a86a0-6dc1-4f67-b06c-be57d5ff3410",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+------------+----------+----------------+--------------------+------+-------------+----------+---+\n",
      "|Acceleration|Cylinders|Displacement|Horsepower|Miles_per_Gallon|                Name|Origin|Weight_in_lbs|      Year| aa|\n",
      "+------------+---------+------------+----------+----------------+--------------------+------+-------------+----------+---+\n",
      "|        12.0|        8|       307.0|       130|            18.0|chevrolet chevell...|   USA|         3504|1970-01-01| 16|\n",
      "|        11.5|        8|       350.0|       165|            15.0|   buick skylark 320|   USA|         3693|1970-01-01| 16|\n",
      "|        11.0|        8|       318.0|       150|            18.0|  plymouth satellite|   USA|         3436|1970-01-01| 16|\n",
      "|        12.0|        8|       304.0|       150|            16.0|       amc rebel sst|   USA|         3433|1970-01-01| 16|\n",
      "|        10.5|        8|       302.0|       140|            17.0|         ford torino|   USA|         3449|1970-01-01| 16|\n",
      "+------------+---------+------------+----------+----------------+--------------------+------+-------------+----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cars.select(\"*\", F.expr(\"Cylinders * 2 AS aa\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "921d11a6-9179-4a9f-9f1c-5f8e93009f23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+------------+----------+----------------+--------------------+------+-------------+----------+---+\n",
      "|Acceleration|Cylinders|Displacement|Horsepower|Miles_per_Gallon|                Name|Origin|Weight_in_lbs|      Year| aa|\n",
      "+------------+---------+------------+----------+----------------+--------------------+------+-------------+----------+---+\n",
      "|        12.0|        8|       307.0|       130|            18.0|chevrolet chevell...|   USA|         3504|1970-01-01| 16|\n",
      "|        11.5|        8|       350.0|       165|            15.0|   buick skylark 320|   USA|         3693|1970-01-01| 16|\n",
      "|        11.0|        8|       318.0|       150|            18.0|  plymouth satellite|   USA|         3436|1970-01-01| 16|\n",
      "|        12.0|        8|       304.0|       150|            16.0|       amc rebel sst|   USA|         3433|1970-01-01| 16|\n",
      "|        10.5|        8|       302.0|       140|            17.0|         ford torino|   USA|         3449|1970-01-01| 16|\n",
      "+------------+---------+------------+----------+----------------+--------------------+------+-------------+----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cars.selectExpr(\"*\", \"Cylinders * 2 AS aa\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b11e256d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hive'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.catalogImplementation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f56014c-6904-477f-902e-93cc020d6683",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Table or view not found: cars; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [cars], [], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1183/1042192679.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"select * from cars\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0msqlQuery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Table or view not found: cars; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [cars], [], false\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from cars\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de119ac5-9ef0-4946-b975-d45a1254fee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cars.createOrReplaceTempView(\"cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "282ae492-ba12-4cec-908f-2b5f3e26e38b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cars.write.saveAsTable(\"cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c794e7e3-efd2-450e-a18b-915439f6f8ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables from default\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30f78648-7c30-4d19-81ea-3930e2165de5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ad0d8be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|     temp|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql(\"CREATE DATABASE temp\")\n",
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e310fad3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE TABLE temp.person2 (id Int, name String)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c75fc3ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------+\n",
      "|namespace| tableName|isTemporary|\n",
      "+---------+----------+-----------+\n",
      "|     temp|movies_per|      false|\n",
      "|     temp|    person|      false|\n",
      "|     temp|   person2|      false|\n",
      "+---------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables from temp\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25ef9e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"INSERT INTO temp.person2 VALUES (1, 'Tom'), (2, 'Ann')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45a74060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|name|\n",
      "+---+----+\n",
      "|  1| Tom|\n",
      "|  2| Ann|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from temp.person\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f01db8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+------------+----------+----------------+--------------------+------+-------------+----------+\n",
      "|Acceleration|Cylinders|Displacement|Horsepower|Miles_per_Gallon|                Name|Origin|Weight_in_lbs|      Year|\n",
      "+------------+---------+------------+----------+----------------+--------------------+------+-------------+----------+\n",
      "|        12.0|        8|       307.0|       130|            18.0|chevrolet chevell...|   USA|         3504|1970-01-01|\n",
      "+------------+---------+------------+----------+----------------+--------------------+------+-------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cars.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "743b3ecc-5854-47dc-8d7b-2cf7ba4e5c83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cars.createOrReplaceGlobalTempView(\"cars_global\")\n",
    "\n",
    "cars.createGlobalTempView(\"cars_g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbb00441",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.createOrReplaceTempView(\"cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac637861",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------+\n",
      "|namespace| tableName|isTemporary|\n",
      "+---------+----------+-----------+\n",
      "|     temp|movies_per|      false|\n",
      "|     temp|    person|      false|\n",
      "+---------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables from temp\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb52a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = spark.read.option(\"inferSchema\", \"true\").json(\"./dataset/movies.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f36974",
   "metadata": {},
   "source": [
    "- createOrReplaceTempView 이걸로 생성하면 DB 모두에 다 생성된다.\n",
    "- saveAsTable 및 read.table의 경우 db 명시 안하면 default에 저장, db.table 이렇게 명시해서 저장/읽기 하면 특정 db에 저장됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c66598af",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.createOrReplaceTempView(\"temp.movies2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce4048bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.write.saveAsTable(\"temp.movies_per\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da6e216d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-----------+-----------+----------+-----------+-----------+-----------------+------------+----------------------+----------------+-------------------+--------------------+------------+--------+---------------+\n",
      "|       Creative_Type|Director|Distributor|IMDB_Rating|IMDB_Votes|MPAA_Rating|Major_Genre|Production_Budget|Release_Date|Rotten_Tomatoes_Rating|Running_Time_min|             Source|               Title|US_DVD_Sales|US_Gross|Worldwide_Gross|\n",
      "+--------------------+--------+-----------+-----------+----------+-----------+-----------+-----------------+------------+----------------------+----------------+-------------------+--------------------+------------+--------+---------------+\n",
      "|                null|    null|   Gramercy|        6.1|      1071|          R|       null|          8000000|   12-Jun-98|                  null|            null|               null|      The Land Girls|        null|  146083|         146083|\n",
      "|                null|    null|     Strand|        6.9|       207|          R|      Drama|           300000|    7-Aug-98|                  null|            null|               null|First Love, Last ...|        null|   10876|          10876|\n",
      "|                null|    null|  Lionsgate|        6.8|       865|       null|     Comedy|           250000|   28-Aug-98|                  null|            null|               null|I Married a Stran...|        null|  203134|         203134|\n",
      "|                null|    null|  Fine Line|       null|      null|       null|     Comedy|           300000|   11-Sep-98|                    13|            null|               null|Let's Talk About Sex|        null|  373615|         373615|\n",
      "|Contemporary Fiction|    null|    Trimark|        3.4|       165|          R|      Drama|          1000000|    9-Oct-98|                    62|            null|Original Screenplay|                Slam|        null| 1009819|        1087521|\n",
      "+--------------------+--------+-----------+-----------+----------+-----------+-----------+-----------------+------------+----------------------+----------------+-------------------+--------------------+------------+--------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.table(\"temp.movies_per\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511147fc",
   "metadata": {},
   "source": [
    "### repartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93831122-6ea7-4898-a419-49411b82b50f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies = spark.read.option(\"inferSchema\", \"true\").json(\"./dataset/movies.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed5f7416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mv = movies.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6e0bc33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba990c51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----------+----------+-----------+------------+-----------------+------------+----------------------+----------------+--------------------+--------------------+------------+---------+---------------+----+\n",
      "|       Creative_Type|            Director|         Distributor|IMDB_Rating|IMDB_Votes|MPAA_Rating| Major_Genre|Production_Budget|Release_Date|Rotten_Tomatoes_Rating|Running_Time_min|              Source|               Title|US_DVD_Sales| US_Gross|Worldwide_Gross|part|\n",
      "+--------------------+--------------------+--------------------+-----------+----------+-----------+------------+-----------------+------------+----------------------+----------------+--------------------+--------------------+------------+---------+---------------+----+\n",
      "|        Kids Fiction|         Mark Dindal|Walt Disney Pictures|        7.4|     23355|          G|   Adventure|        100000000|   15-Dec-00|                    85|              78| Original Screenplay|The Emperor's New...|        null| 89296573|      169296573|   0|\n",
      "|Contemporary Fiction|          P.J. Hogan|       Sony Pictures|        6.2|     37287|      PG-13|      Comedy|         46000000|   20-Jun-97|                    72|             105| Original Screenplay|My Best Friend's ...|        null|126813153|      287200000|   1|\n",
      "|  Historical Fiction|Francis Ford Coppola|                 MGM|        8.6|    173141|          R|      Action|         31500000|   15-Aug-79|                    98|            null|Based on Book/Sho...|      Apocalypse Now|     3479242| 78800000|       78800000|   2|\n",
      "|  Historical Fiction|         Mary Harron|           Lionsgate|        7.4|     99424|          R|Black Comedy|          8000000|   14-Apr-00|                    66|            null|Based on Book/Sho...|     American Psycho|        null| 15070285|       28674417|   3|\n",
      "+--------------------+--------------------+--------------------+-----------+----------+-----------+------------+-----------------+------------+----------------------+----------------+--------------------+--------------------+------------+---------+---------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mv.withColumn('part', F.spark_partition_id()).drop_duplicates(subset=['part']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cfc2224-1961-4c65-ab7a-af61ad5eb586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies = spark.read.option(\"inferSchema\", \"true\").json(\"./dataset/movies.json\")\n",
    "\n",
    "movies2 = movies.repartition(6, \"Major_Genre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0260cbc3-cc02-40ee-aec0-933e1d6b7ea4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.groupBy(\"Major_Genre\").count().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5e1010a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies2.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f834658d-5b92-4bba-bf36-02ff60f58cff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+\n",
      "|        Major_Genre|part|\n",
      "+-------------------+----+\n",
      "|               null|   0|\n",
      "|             Comedy|   0|\n",
      "|       Black Comedy|   0|\n",
      "|            Musical|   1|\n",
      "|  Thriller/Suspense|   2|\n",
      "|             Horror|   2|\n",
      "|          Adventure|   3|\n",
      "|             Action|   3|\n",
      "|            Western|   3|\n",
      "|        Documentary|   3|\n",
      "|    Romantic Comedy|   4|\n",
      "|Concert/Performance|   4|\n",
      "|              Drama|   5|\n",
      "+-------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies2.withColumn('part', F.spark_partition_id()).drop_duplicates(subset=['Major_Genre','part']).select('Major_Genre', 'part').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4196d583-d0b7-4c4d-8775-666ddac1a9ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies2.write.option(\"header\",True).mode(\"overwrite\").csv('./temp_space/movies')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973a5e56-c8d2-425a-8073-72f0de8aa18c",
   "metadata": {},
   "source": [
    "## partitionBy\n",
    "- 저장시 partitionBy 컬럼에 따라 폴더가 나뉘어져 들어가는데 end단에 저장된 파일에는 그 컬럼이 빠져있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5aeac60e-f600-45b5-9254-23dcbc67b0b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies = spark.read.option(\"inferSchema\", \"true\").json(\"./dataset/movies.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ed5a221-2124-4d7e-a4c3-c40c09269037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies.write.option(\"header\",True).partitionBy(\"Major_Genre\").mode(\"overwrite\").csv('./temp_space/movies2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e4f353-01c1-4dd1-b40e-36c328163411",
   "metadata": {},
   "source": [
    "## DataFrame.transform() - DF에 대해 가공할 내용들을 함수로 정의하여 한방에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a21c2904-7202-42c0-a905-fc5e5bedf948",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-----------+-----------+----------+-----------+-----------+-----------------+------------+----------------------+----------------+-------------------+--------------------+------------+--------+---------------+\n",
      "|       Creative_Type|Director|Distributor|IMDB_Rating|IMDB_Votes|MPAA_Rating|Major_Genre|Production_Budget|Release_Date|Rotten_Tomatoes_Rating|Running_Time_min|             Source|               Title|US_DVD_Sales|US_Gross|Worldwide_Gross|\n",
      "+--------------------+--------+-----------+-----------+----------+-----------+-----------+-----------------+------------+----------------------+----------------+-------------------+--------------------+------------+--------+---------------+\n",
      "|                null|    null|   Gramercy|        6.1|      1071|          R|       null|          8000000|   12-Jun-98|                  null|            null|               null|      The Land Girls|        null|  146083|         146083|\n",
      "|                null|    null|     Strand|        6.9|       207|          R|      Drama|           300000|    7-Aug-98|                  null|            null|               null|First Love, Last ...|        null|   10876|          10876|\n",
      "|                null|    null|  Lionsgate|        6.8|       865|       null|     Comedy|           250000|   28-Aug-98|                  null|            null|               null|I Married a Stran...|        null|  203134|         203134|\n",
      "|                null|    null|  Fine Line|       null|      null|       null|     Comedy|           300000|   11-Sep-98|                    13|            null|               null|Let's Talk About Sex|        null|  373615|         373615|\n",
      "|Contemporary Fiction|    null|    Trimark|        3.4|       165|          R|      Drama|          1000000|    9-Oct-98|                    62|            null|Original Screenplay|                Slam|        null| 1009819|        1087521|\n",
      "+--------------------+--------+-----------+-----------+----------+-----------+-----------+-----------------+------------+----------------------+----------------+-------------------+--------------------+------------+--------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies = spark.read.option(\"inferSchema\", \"true\").json(\"./dataset/movies.json\")\n",
    "\n",
    "movies.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cb9d4590-1da7-4705-aa28-adb34b783798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def df_groupby(df, cols: str):\n",
    "    df_ = df.groupBy(cols).count().orderBy(\"count\", ascending=False)\n",
    "    print(df_.count())\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f6482f37-75c5-4017-b231-a1b8cc9e3ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def df_concat(df, cols: str, letter: str):\n",
    "    df_ = df.withColumn(\"add\", F.concat(F.col(cols), F.lit(letter)))\n",
    "    return df_.select(cols, \"add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9d6e1e9a-92e4-41b4-8cd2-9d2d244359bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "+--------------------+-----+\n",
      "|       Creative_Type|count|\n",
      "+--------------------+-----+\n",
      "|Contemporary Fiction| 1453|\n",
      "|                null|  446|\n",
      "|  Historical Fiction|  350|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.transform(df_groupby, \"Creative_Type\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bfa3733-4d14-4e58-9fa3-7bb99cc38068",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|Major_Genre|      add|\n",
      "+-----------+---------+\n",
      "|       null|     null|\n",
      "|      Drama| Drama@@@|\n",
      "|     Comedy|Comedy@@@|\n",
      "+-----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.transform(df_concat, \"Major_Genre\", \"@@@\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a655175-cb8c-49fd-8408-086fcbcc34da",
   "metadata": {},
   "source": [
    "## functions.transform -> array 형식으로 들어가있는 row를 다룰 때 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "83435ab8-d349-4431-a5b7-d7f81d2b4fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies2 = movies.na.drop(how='all', subset = ['Major_Genre', 'Distributor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "90f0d85d-f025-41cb-ac2a-c005e3d6f6dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------------------------------------------------------------------------------------------------------+\n",
      "|Distributor     |Major_Genre2                                                                                                      |\n",
      "+----------------+------------------------------------------------------------------------------------------------------------------+\n",
      "|null            |[Action, Adventure, Romantic Comedy, Comedy, Drama, Horror, Documentary, Black Comedy, Musical, Thriller/Suspense]|\n",
      "|20th Century Fox|[Action, Adventure, Romantic Comedy, Comedy, Drama, Horror, Western, Musical, Thriller/Suspense]                  |\n",
      "|3D Entertainment|[Documentary]                                                                                                     |\n",
      "+----------------+------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies3 = movies2.groupBy(\"Distributor\").agg(F.collect_set(F.col(\"Major_Genre\")).alias(\"Major_Genre2\"))\n",
    "movies3.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8a7eb6bc-96a2-4e68-adca-7d5e04e714fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------+\n",
      "|trans                                                                                                             |\n",
      "+------------------------------------------------------------------------------------------------------------------+\n",
      "|[ACTION, ADVENTURE, ROMANTIC COMEDY, COMEDY, DRAMA, HORROR, DOCUMENTARY, BLACK COMEDY, MUSICAL, THRILLER/SUSPENSE]|\n",
      "|[ACTION, ADVENTURE, ROMANTIC COMEDY, COMEDY, DRAMA, HORROR, WESTERN, MUSICAL, THRILLER/SUSPENSE]                  |\n",
      "|[DOCUMENTARY]                                                                                                     |\n",
      "|[ACTION]                                                                                                          |\n",
      "|[DRAMA]                                                                                                           |\n",
      "+------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies3.select(F.transform(\"Major_Genre2\", lambda x: F.upper(x)).alias('trans')).show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fd673f-18e0-4250-b122-3bd437bf98c7",
   "metadata": {},
   "source": [
    "## broadcast\n",
    "- A와 B를 Join 할때, A의 크기가 B에 비해 너무나 큰 상황일때는 단순 join으로 둘을 엮는게 비효율적일 수 있다. 특히 A의 어떠한 value를 B의 특정 value로 치환하고자 하는 목적일때는 더더욱 그렇다.\n",
    "- 이럴 때는 B를 broadcast 변수로 만들어 모든 node에 복제한 후 Join하는 것과 동일한 효과를 shuffle 없이 얻을 수 있다.\n",
    "- 단순히 join을 하게되면 shuffle이 일어나 broadcast를 쓴 것에 비해 효율이 낮다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0b84ec-19cc-4848-a87f-ec6f76caa8b0",
   "metadata": {},
   "source": [
    "#### 1) join 상황과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1190e363-ea46-4f10-9825-f36df8ec70fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark =  SparkSession \\\n",
    "        .builder \\\n",
    "        .appName('pyspark-broadcast') \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2c999c6-c42a-4322-930e-19b1d165b774",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = [(\"101\", 'Department 1'),\n",
    "        (\"102\", 'Department 2'),\n",
    "        (\"103\", 'Department 3'),\n",
    "        (\"104\", 'Department 4'),\n",
    "        (\"105\", 'Department 5'),\n",
    "        (\"106\", 'Department 6'),\n",
    "        (\"107\", 'Department 7')]\n",
    "\n",
    "columns = ['department_id', 'dept_name']\n",
    "\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf52a2bf-0c1b-4efc-a72f-a55b5606a98d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emp = spark.read.csv(\"/home/workspace/dataset/emp.csv\", header = True)\n",
    "\n",
    "# emp.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1dd479ba-329d-45e3-866b-a721d08aa8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-------------+---+------+------+----------+------------+\n",
      "|department_id|employee_id|         name|age|gender|salary| hire_date|   dept_name|\n",
      "+-------------+-----------+-------------+---+------+------+----------+------------+\n",
      "|          101|        001|     John Doe| 30|  Male| 50000|2015-01-01|Department 1|\n",
      "|          101|        002|   Jane Smith| 25|Female| 45000|2016-02-15|Department 1|\n",
      "|          101|        007|James Johnson| 42|  Male| 70000|2012-03-15|Department 1|\n",
      "|          107|        014|    Emily Lee| 26|Female| 46000|2019-01-01|Department 7|\n",
      "|          107|        016|  Kelly Zhang| 30|Female| 49000|2018-04-01|Department 7|\n",
      "|          104|        010|     Lisa Lee| 27|Female| 47000|2018-08-01|Department 4|\n",
      "|          104|        011|   David Park| 38|  Male| 65000|2015-11-01|Department 4|\n",
      "|          104|        018|    Nancy Liu| 29|Female| 50000|2017-06-01|Department 4|\n",
      "|          102|        003|    Bob Brown| 35|  Male| 55000|2014-05-01|Department 2|\n",
      "|          102|        004|    Alice Lee| 28|Female| 48000|2017-09-30|Department 2|\n",
      "|          102|        008|     Kate Kim| 29|Female| 51000|2019-10-01|Department 2|\n",
      "|          102|        020|    Grace Kim| 32|Female| 53000|2018-11-01|Department 2|\n",
      "|          103|        005|    Jack Chan| 40|  Male| 60000|2013-04-01|Department 3|\n",
      "|          103|        006|    Jill Wong| 32|Female| 52000|2018-07-01|Department 3|\n",
      "|          103|        009|      Tom Tan| 33|  Male| 58000|2016-06-01|Department 3|\n",
      "|          103|        019|  Steven Chen| 36|  Male| 62000|2015-08-01|Department 3|\n",
      "|          106|        013|    Brian Kim| 45|  Male| 75000|2011-07-01|Department 6|\n",
      "|          106|        015|  Michael Lee| 37|  Male| 63000|2014-09-30|Department 6|\n",
      "|          105|        012|   Susan Chen| 31|Female| 54000|2017-02-15|Department 5|\n",
      "|          105|        017|  George Wang| 34|  Male| 57000|2016-03-15|Department 5|\n",
      "+-------------+-----------+-------------+---+------+------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result1 = emp.join(df, [\"department_id\"], 'left')\n",
    "\n",
    "result1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f550b280-3197-4f03-b88f-aceb0a7243f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c278ba-93c8-4c53-9163-0925aa9b55e7",
   "metadata": {},
   "source": [
    "#### 2) Broadcast 상황"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16d12f48-5eb0-46fb-8bbf-68289412b1bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dept_names = {\"101\" : 'Department 1', \n",
    "              \"102\" : 'Department 2', \n",
    "              \"103\" : 'Department 3', \n",
    "              \"104\" : 'Department 4',\n",
    "              \"105\" : 'Department 5', \n",
    "              \"106\" : 'Department 6', \n",
    "              \"107\" : 'Department 7'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db8588ec-a67b-4f26-9521-8c6cee8a6e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "broadcast_dept_names = spark.sparkContext.broadcast(dept_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91da62f3-4152-41bc-8a75-c03dea6a6495",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.broadcast.Broadcast'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'101': 'Department 1',\n",
       " '102': 'Department 2',\n",
       " '103': 'Department 3',\n",
       " '104': 'Department 4',\n",
       " '105': 'Department 5',\n",
       " '106': 'Department 6',\n",
       " '107': 'Department 7'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(broadcast_dept_names))\n",
    "broadcast_dept_names.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea5b4697-f76f-4aca-b917-49332bd85c1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@F.udf\n",
    "def get_dept_names(dept_id):\n",
    "    return broadcast_dept_names.value.get(dept_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1040ca8b-7d9d-4dc7-b4dc-494db916f2c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emp = spark.read.csv(\"/home/workspace/dataset/emp.csv\", header = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c982a7a7-19dc-41c0-adf0-da0583512893",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+------------+\n",
      "|employee_id|department_id|         name|age|gender|salary| hire_date|   dept_name|\n",
      "+-----------+-------------+-------------+---+------+------+----------+------------+\n",
      "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|Department 1|\n",
      "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|Department 1|\n",
      "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|Department 2|\n",
      "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|Department 2|\n",
      "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|Department 3|\n",
      "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|Department 3|\n",
      "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|Department 1|\n",
      "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|Department 2|\n",
      "|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|Department 3|\n",
      "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|Department 4|\n",
      "|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|Department 4|\n",
      "|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|Department 5|\n",
      "|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|Department 6|\n",
      "|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|Department 7|\n",
      "|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|Department 6|\n",
      "|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|Department 7|\n",
      "|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|Department 5|\n",
      "|        018|          104|    Nancy Liu| 29|Female| 50000|2017-06-01|Department 4|\n",
      "|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|Department 3|\n",
      "|        020|          102|    Grace Kim| 32|Female| 53000|2018-11-01|Department 2|\n",
      "+-----------+-------------+-------------+---+------+------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_final = emp.withColumn(\"dept_name\", get_dept_names(F.col(\"department_id\")))\n",
    "\n",
    "emp_final.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545db9f0-bf73-46f9-8a74-a92038ba318c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1889bfe7-7362-48a2-9d52-d299e7c1daef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark =  SparkSession \\\n",
    "        .builder \\\n",
    "        .appName('accumulator') \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "da442704-51ac-4d99-a5b1-3b0aa50d7757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cars = spark.read.option(\"inferSchema\", \"true\").json(\"./dataset/cars.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "617a89c9-2cd9-4456-a548-7ebac08177c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cars = cars.filter(F.col(\"Origin\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "adfbd019-ed60-481f-829a-4729a9a99953",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|sum(Cylinders)|\n",
      "+--------------+\n",
      "|          1596|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cars.filter(F.col(\"Origin\") == 'USA').agg(F.sum(\"Cylinders\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3151f339-093c-4350-b9f3-dad68b7dd7df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accum = spark.sparkContext.accumulator(0)\n",
    "\n",
    "def sum_horsepower(origin, cyl):\n",
    "    if origin == \"USA\":\n",
    "        accum.add(cyl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "04d86e04-0c79-44b3-a549-3db3463c55c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 기준 컬럼에 null이 있으면 에러가 난다.\n",
    "\n",
    "cars.foreach(lambda row : sum_horsepower(row.Origin, row.Cylinders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6dfe8006-d08a-4175-b212-ee992e02e7a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1596"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accum.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "988405c4-0ef0-40bd-8d31-a20b8c6a88d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
